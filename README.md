# sparker
Postgres - https://postgresapp.com/downloads.html
GUI - https://www.pgadmin.org

db\table = task\task

inserting - default user (postgres)

Main class - src\main\scala\Main 

first build - then run

table config - WebService.scala bottom of the file

## Working with AVRO

http://avro.apache.org/docs/current/gettingstartedjava.html

https://spark.apache.org/docs/latest/sql-data-sources-avro.html



###Задача

Часть 1 – модуль загрузки.

Цель – из внешнего источника взять данные и отправить их в Платформу Кибербезопасности (хранилище данных) – а Платформу
  будут моделировать следующие приложения.
  
- [x] Есть файлы csv в локальной файловой системе – event и ext_fact.
Читаем их через Spark.

Валидируем.
 - [x] Парсинг YAML. Обязательность полей, соответствие форматам и т.д. – правила в виде yml
 -файла, указаны не для всех полей, если для какого-то поля не указаны – не валидируем его. Смысл правил расписан в начале yml-файла в комментарии.
 - [ ] Если в какой-то строке невалидные значения – вся строка откладывается в отдельный файл error.csv.
 - [ ] Джойним (inner join) датафреймы event и ext_fact по полю event_id.
 - [ ] Полученный датафрейм фильтруем по двум условиям: type_operation = RurPayment и event_channel = MOBILE.
 - [x] Каждую строку полученного датафрейма (каждую транзакцию) сериализуем в JSON
 - [x] и отправляем на REST API второго модуля (Http-метод POST, в теле JSON).
 - [ ] Если не отправляется (connection refused
  или какое-то такое исключение возникает), то ждем какое-то время и пытаемся ещё раз. Структура сообщения – плоский JSON, все поля на одном уровне.
 - [ ] Поля, которые должны быть в JSON-е: event_id,event_time,event_channel,sub_channel,event_type,sub_type,
 event_description,transaction_amount,transaction_sender_account_number,transaction_beneficiar_account_number,ccaf_dt_load,event_dt,
 issue_date_card_owner,number_dul,account_number_of_recipient,number_card_recepient,payer_card_number,recepient_bik,
 recepient_inn,recepient_fio,client_phone_number
 - [x] Параметры приложения: путь к файлу event, путь к файлу ext_fact, путь к файлу конфигурации (validate.yml
 ), адрес REST API второго модуля, количество попыток отправки и интервал между ними в секундах.
 - [x] Параметры должны читаться из командной строки.
 - [ ] В результате должны получить исполняемый джарник, который можно запустить командой «java –jar some.jar [key=value
 , key=value, …]»

Часть 2 – сервис (интерфейсный модуль).
- [x] Веб-сервис, висит на порту, слушает входящие POST-запросы. Адрес (endpoint, путь) согласовать с автором загрузки.
 Протокол HTTP без SSL пока что и без аутентификации.
- [x] Очень простая логика, нужно только тело запроса (JSON) сохранить в БД Postgres. Имя схемы и таблицы на усмотрение
  автора (согласовать с автором модуля парсинга). Поля таблицы: id, дата приёма сообщения, статус (0 – сохранено, 1 –
  обработано и загружено в Платформу, 2 – обработано с ошибкой), текст ошибки, тело запроса. Статус при сохранении
  ставим 0, остальные ставит следующий модуль. Текст ошибки при сохранении NULL.
Параметры приложения: хост и порт, на котором будет висеть приложение; данные для подключения к БД, логин/пароль; можно
  также имя схемы/таблицы вынести в параметры, чтобы сервис мог писать в разные таблицы.

Часть 3 – парсинг и сохранение в Платформу.
- [x] Spark-приложение, запускается вручную, или по расписанию, т.е. независимо от сервиса.
- [x] Приложение читает из Postgres новые входящие запросы в статусе 0, парсит их средствами Spark (по приложенной Avro
-схеме – файл schema.json).
- [ ] Если в теле запроса невалидный JSON – обновляем статус на 2 (ошибка), пишем текст ошибки «invalid JSON
» или подобный, на усмотрение. При всех остальных также сохранять по этим строкам статус 2, приложение вообще не должно фатально завершаться из-за ошибок обработки сообщений (хотя вообще и может падать из-за каких-то общих проблем, типа нехватки памяти).
- [ ] Сообщения, которые успешно распарсили, сохраняем в Платформу (ну физически пусть это будут Parquet
-файлы) в две таблицы (2 логических слоя):
1.       Src-слой – данные ровно в том виде, как они пришли из внешнего источника. По сути это аналог таблицы в Postgres. Поля src-слоя – ID (можно генерировать рандомный UUID для этого), дата создания строки в формате YYYYMMDD (партиционировать датафрйем по этому полю перед записью в Parquet), и текст исходного сообщения (сам JSON, вот как есть).
2.       Inc-слой – данные в табличном виде, полезном для просмотра, анализа и выполнения SQL. То есть тут должен получиться parquet-файл с полями, имена полей как в JSON-е, типы в соответствии с Avro-схемой.
- [x] Параметры приложения: данные для подключения к БД, логин/пароль; путь к файлу Avro
-схемы, имя схемы/таблицы в Postgres, откуда читать сообщения (можно будет натравливать с разными схемами на разные таблицы);

Общие пожелания ко всем модулям:
- [x] 1.       Текстовый лог писать (библиотеку логирования log4j2
 можно использовать). События и уровни логирования на усмотрения авторов, по логу должно быть понятно человеку со стороны, что происходит (сотруднику группы сопровождения, который мало что знает о бизнес-смысле приложений). Т.е. какие-то логические ошибки и ошибки валидации должны быть видны в логе.
- [ ] 2.       Все джарники должны быть fat jar, т.е. запускаться командой java –jar
 – все зависимости должны быть упакованы туда. Пока так сделаем, для простоты. В результате там, где используется Spark, получатся джарники размером в сотни мегабайт, потому что Spark сам по себе большой – ну и ладно
- [x] 3.       Версия Spark – 2.4.0, версия Scala – 2.11

- [ ] Развитие на будущее:
1.       Серверная SSL-аутентификация между загрузкой и сервисом – автор сервиса выпускает самоподписанный сертификат, настраивает сервис на его использование, загрузка его добавляет в своё хранилище доверенных сертификатов и по нему проверяет подлинность сервиса
